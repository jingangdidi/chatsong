# 使用说明 & 功能介绍

## 开启新对话
- 页面左侧`开启新对话`是`config.txt`中自定义的prompt，选择其中一个就会开启新对话，当前对话使用的prompt名称会显示在页面左侧`当前prompt`中。
- `config.txt`中`maxage`设置当前使用的对话，在最后一次提问后多长时间内，再次打开页面还显示该对话，如果超过了`maxage`则会开启一个新对话，之前的对话可通过在`uuid`中输入对话的uuid访问。例如默认`1DAY`，当前对话最后一次提问是9点，第二天9点之前再次打开页面（或没关闭页面直接提问），还显示这个对话，可继续提问，若在9点后打开页面（或没关闭页面直接提问），会自动开启一个新对话。这个设置是为了避免不相关的问题都在同一个对话中。
- 每次提问时都可以填写或修改`当前对话名称`。
<img src="https://github.com/jingangdidi/chatsong/raw/main/doc/start_new_chat_zh.png" width="20%">

## 连续的问题或答案
- 提交问题后不会直接向LLM发送求取，需要在不输入内容时再按一次回车才会确认发送，这样的好处是可以连续输入多次，比如把一个复杂问题分多次描述。
- 如果对当前使用的模型的回答不满意，可以直接按回车（在此之前可以在页面左侧`模型`中切换模型），会忽略最后一次提问后面的所有回答，重新进行回答。
- 如果提问时在页面左侧`调用工具`中选择了工具，则LLM每次调用工具的结果都会以单独一条消息返回，页面显示的就是多个答案消息框。
<img src="https://github.com/jingangdidi/chatsong/raw/main/assets/image/QA-pair.png" width="50%">

## 上下文消息数
- 该下拉选项可以自定义每次提问时，将之前的多少条信息也一起发送给模型。
- 一条信息表示用户输入的一个问题或模型回答的一条答案。
- 一对Q&A表示`连续的多个输入`+`连续的多个输出`，这其实不是限制具体消息数，而是限制对话的轮数，比如我发送了一张图片，然后又发送了一条关于这张图片问题，模型A给出答案，我不满意，又换模型B再次提问，模型B也返回一条答案信息，这些信息（2条提问+2条回答）共同组成了一轮对话，即一对Q&A。
- `prompt + xxx`表示提问时，把开启该对话时选择的prompt作为第一条信息，与当前问题和上下文信息一起发送给模型，如果开启该对话时选择的是`无prompt`，则等同于不加prompt。
<img src="https://github.com/jingangdidi/chatsong/raw/main/doc/select_context_length_zh.png" width="20%">

## 调用工具
- 默认是常规问答模式，不使用工具，在页面左侧`调用工具`中选择了工具，则会调用工具进行回答，每次调用工具的结果都会以一条单独消息返回页面，直到模型不再调用工具则回答结束。
- 如果是复杂问题，可以开启`计划模式`（仅调用工具时有效），会先制定计划，先把发送的问题拆分为多个子问题，然后逐一完成，每步的结果都会以一条单独消息返回页面。如果模型自身和选择的工具都无法完成发送的问题，则会停止回答，并返回一条信息解释缺少什么能力。
- 调用工具支持选择同一分组的所有工具，也可以只选择一个工具，选择的工具越多，消耗的token也越多。
- 目前内置了`file system`工具，主要包括文件读写、压缩解压等访问本地数据的能力。
- 可以在`config.txt`中自定义MCP的stdio工具，比如读写excel、访问网络，具体格式见示例`config_template.txt`。
- 可以在`config.txt`中自定义自己写的外部工具，比如自己写的python脚本（注意参数需要用`--`指定），具体格式见示例`config_template.txt`。
<img src="https://github.com/jingangdidi/chatsong/raw/main/doc/call_tools_zh.png" width="20%">

## 压缩总结上下文
- 当前对话消息很多时，每次提问都带上太多消息记录会消耗很多token，如果之前问答信息与当前问题无关，可以使用`上下文消息数`限制发送当前问题时包含的消息记录。
- 如果对话消息很多，且都与当前问题相关，还想减少token用量或上下文空间，可以点击页面左下角压缩总结按钮（左起第四个），会将`上下文消息数`范围内的问答信息压缩总结为一条信息。
<img src="https://github.com/jingangdidi/chatsong/raw/main/doc/left_button_button.png" width="50%">

## token用量统计
- 页面左侧最后3项分别显示向LLM发送请求的总token、LLM返回的总token、最后一次提问发送和接收的总token。
- 此外鼠标放在每个回答消息框上时，还会显示相应回复信息的token数。
<img src="https://github.com/jingangdidi/chatsong/raw/main/doc/token_zh.png" width="20%">

## 上传附件进行提问
- 点击输入框左侧的上传附件按钮，可以选择上传图片、文本文件、音频文件、pdf文件、zip压缩文件。
- 图片只支持`png`、`.jpg`、`.jpeg`。
- 音频只支持`.flac`、`.mp3`、`.mp4`、`.mpeg`、`.mpga`、`.m4a`、`.ogg`、`.wav`、`.webm`。
- pdf文件如果后缀是小写`.pdf`则会将每页内容转为图片，配合`qwen3-vl`模型进行问答，否则会提取每页的文本内容作为输入的问题。
- 如果是zip压缩文件，则会递归读取每个文件的内容，合并为一个codebase，且含有原始路径信息，方便对项目代码进行提问。
- 如果是其他格式文件，则会默认作为文本文件，读取全部内容进行提问。

## 基于图像问答
- 模型需要支持图片提问，例如qwen3-vl系列模型。
- 点击输入框左侧的上传附件按钮，可以选择上传图片或pdf文件。
- 如果是pdf图片则会自动将每页转为一张图片（每页大约1000个token），每页的图片会作为一条单独消息框显示在页面右侧，再次按下回车前可以点击消息框上方的删除按钮，手动删除不重要的图片页，比如最后的参考文献，以节省token。
<img src="https://github.com/jingangdidi/chatsong/raw/main/doc/upload_pdf_to_image.png" width="20%">

## 下载当前对话记录
- 每个对话的记录都以`json`格式保存在输出路径下相应uuid文件中中。
- 可以点击页面左下角保存按钮（左起第二个），将当前对话保存为一个无依赖的`html`文件。
<img src="https://github.com/jingangdidi/chatsong/raw/main/doc/left_button_button.png" width="50%">

## 无痕模式
- 如果不想将当前对话保存至本地输出路径，可以点击页面左下角的无痕模式按钮（左起第五个）。
- 图标为黑色眼镜表示已开启无痕模式，关闭当前页面再次打开，或刷新当前页面，都将丢失当前对话的记录、关闭chatsong服务时不会自动保存该对话，直接丢弃。
<img src="https://github.com/jingangdidi/chatsong/raw/main/doc/left_button_button.png" width="50%">

## 内网多用户访问
- 在内网电脑A通过命令行参数`-a <ip>`，例如`-a 192.168.1.5`，指定ip地址开启chatsong服务，则内网的其他用户可以通过`http://192.168.1.5:8080/v1`调用chatsong服务。
- chatsong不区分每个对话属于哪个用户，都以uuid为对话id保存在电脑A的输出路径下。
- 如果要分享自己的对话给其他人，分享对话uuid即可，对方在自己页面左侧背面（点击左下角设置按钮）的uuid输入框内输入分享的uuid，在提问输入框内输入任意内容回车，即可跳转到该对话。
